{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training a bigram model with a Greek corpus\n",
        "- using spacy within a jupyter notebook\n",
        "- we will observe the probabilities of 2 test sample Greek sentences against the model to calculate its probability of occurring given the vocabulary and their individual perplexities\n",
        "- we will finally use the trained model to generate sentences in Greek"
      ],
      "metadata": {
        "id": "1T9qLeYrAyxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1VKBIlJBKKs",
        "outputId": "6ec20fc9-650a-4cef-963c-f7607e3fc305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Τρώω φρούτα κάθε μέρα.\n",
            " Τρώω ψωμί με βούτυρο.\n",
            " Τρώω ένα μήλο το πρωί.\n",
            " Τρώω σαλάτα με ντομάτα.\n",
            " Τρώω ζυμαρικά για μεσημεριανό.\n",
            " Τρώω κοτόπουλο για δείπνο.\n",
            " Τρώω αυγά το Σαββατοκύριακο.\n",
            " Τρώω ρύζι με λαχανικά.\n",
            " Τρώω γιαούρτι με μέλι.\n",
            " Τρώω τυρί και ελιές.\n",
            " Αγαπώ τα φρούτα, ειδικά τα μήλα.\n",
            " Έχεις ψωμί;\n",
            " Κάθε πρωί τρώω ένα μήλο.\n",
            " Θέλω να φάω σαλάτα με ντομάτες.\n",
            " Η σούπα έχει κοτόπουλο και λαχανικά.\n",
            " Πόσο κοστίζει το ψωμί;\n",
            " Πίνω γάλα με το μήλο μου.\n",
            " Μετά το δείπνο, τρώμε συχνά φρούτα.\n",
            " Στη σαλάτα, βάζω πάντα ντομάτες.\n",
            " Ποιος έφαγε το ψωμί;\n",
            " Το κοτόπουλο είναι το αγαπημένο μου φαγητό.\n",
            " Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ;\n",
            " Αυτή η μηλόπιτα είναι πολύ νόστιμη.\n",
            " Πού αγόρασες αυτά τα φρέσκα φρούτα;\n",
            " Φτιάχνω σαλάτα με ντομάτες και αγγούρια.\n",
            " Θα πιείτε γάλα ή χυμό;\n",
            " Τα παιδιά δεν τρώνε πολύ ψωμί.\n",
            " Αυτές οι ντομάτες είναι πολύ ώριμες.\n",
            " Στο πρωινό μου πάντα έχω ένα μήλο.\n",
            " Τα φρούτα είναι καλά για την υγεία.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.lang.el import Greek\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "# import files\n",
        "from typing import Tuple\n",
        "from google.colab import files\n",
        "\n",
        "# this corpus is not pasting correctly from HW instructions, therefore some extra spaces were added to aid tokenization\n",
        "ori_texts = '''Τρώω φρούτα κάθε μέρα.\n",
        " Τρώω ψωμί με βούτυρο.\n",
        " Τρώω ένα μήλο το πρωί.\n",
        " Τρώω σαλάτα με ντομάτα.\n",
        " Τρώω ζυμαρικά για μεσημεριανό.\n",
        " Τρώω κοτόπουλο για δείπνο.\n",
        " Τρώω αυγά το Σαββατοκύριακο.\n",
        " Τρώω ρύζι με λαχανικά.\n",
        " Τρώω γιαούρτι με μέλι.\n",
        " Τρώω τυρί και ελιές.\n",
        " Αγαπώ τα φρούτα, ειδικά τα μήλα.\n",
        " Έχεις ψωμί;\n",
        " Κάθε πρωί τρώω ένα μήλο.\n",
        " Θέλω να φάω σαλάτα με ντομάτες.\n",
        " Η σούπα έχει κοτόπουλο και λαχανικά.\n",
        " Πόσο κοστίζει το ψωμί;\n",
        " Πίνω γάλα με το μήλο μου.\n",
        " Μετά το δείπνο, τρώμε συχνά φρούτα.\n",
        " Στη σαλάτα, βάζω πάντα ντομάτες.\n",
        " Ποιος έφαγε το ψωμί;\n",
        " Το κοτόπουλο είναι το αγαπημένο μου φαγητό.\n",
        " Μπορώ να έχω λίγο περισσότερο ψωμί, παρακαλώ;\n",
        " Αυτή η μηλόπιτα είναι πολύ νόστιμη.\n",
        " Πού αγόρασες αυτά τα φρέσκα φρούτα;\n",
        " Φτιάχνω σαλάτα με ντομάτες και αγγούρια.\n",
        " Θα πιείτε γάλα ή χυμό;\n",
        " Τα παιδιά δεν τρώνε πολύ ψωμί.\n",
        " Αυτές οι ντομάτες είναι πολύ ώριμες.\n",
        " Στο πρωινό μου πάντα έχω ένα μήλο.\n",
        " Τα φρούτα είναι καλά για την υγεία.'''\n",
        "print(ori_texts)\n",
        "\n",
        "# using spacy's pretrained Greek model\n",
        "# !pip install https://github.com/explosion/spacy-models/releases/download/el_core_news_sm-3.5.0/el_core_news_sm-3.5.0.tar.gz\n",
        "nlp = spacy.load(\"el_core_news_sm\")\n",
        "\n",
        "# simply remove new lines... keeping all punctuation marks for the sentence generation that will happen in Q4\n",
        "preprocessed_texts = ori_texts.lower().replace('\\n', '')\n",
        "\n",
        "## HELPER METHODS\n",
        "def tokenize(corpus: str) -> list:\n",
        "  doc = nlp(corpus)\n",
        "  tokens = [token.text for token in doc]\n",
        "  # print(tokens)\n",
        "  return tokens\n",
        "\n",
        "def get_unigram_count(tokens: list) -> dict:\n",
        "  res = {}  # dictionary for unigram counts\n",
        "  for token in tokens:\n",
        "      res[token] = res.get(token, 0) + 1\n",
        "\n",
        "  return res\n",
        "\n",
        "def get_bigram_count(tokens: list) -> dict:\n",
        "  res = {}   # dictionary for bigram counts\n",
        "      # count bigrams\n",
        "  for i in range(len(tokens) - 1):\n",
        "      bigram = (tokens[i], tokens[i + 1])\n",
        "      res[bigram] = res.get(bigram, 0) + 1 # keep a frequency count of each bigram within the corpus\n",
        "  return res\n",
        "\n",
        "# DONT NEED THIS METHOD?\n",
        "# def add_all_possible_bigrams(vocabulary, bigram_count_map: dict) -> dict:\n",
        "#   '''your code here'''\n",
        "#   return bigram_count_map\n",
        "\n",
        "def get_probability_smoothing(count_map: dict, v: int, N: int) -> dict:\n",
        "  res = {key: (count + 1) / (N + v) for key, count in count_map.items()}\n",
        "  return res\n",
        "\n",
        "def estimate_probability_preplexity_product(sentence, unigram_count_map, bigram_count_map: dict, V: int) -> Tuple[float, float]:\n",
        "  tokens = tokenize(sentence) # tokenize sentence\n",
        "  log_prob_sum = 0.0\n",
        "\n",
        "  # iterate through all tokens and calculate bigram probabilities\n",
        "  for i in range(len(tokens)-1):\n",
        "      bigram = (tokens[i], tokens[i+1])\n",
        "      prob = bigram_count_map.get(bigram, 1/V)\n",
        "      log_prob_sum += math.log(prob)\n",
        "\n",
        "  # json file needs actual prob, not log sum prob\n",
        "  actual_prob = math.exp(log_prob_sum)  # convert log probability to actual probability\n",
        "  perplexity = actual_prob ** (-1 / len(tokens))  # calculate perplexity of sentence\n",
        "\n",
        "  return actual_prob, perplexity  #return Tuple[float, float]\n",
        "\n",
        "# This method is never called on by the automated graded template below, therefore I just commented it out and did both log sum probability + perplexity in one method\n",
        "# def estimate_probability_perplexity_log_sum(sentence, unigram_count_map, bigram_count_map: dict, V: int) -> Tuple[float, float]:\n",
        "#   '''your code here'''\n",
        "#   return Tuple[float, float]\n",
        "\n",
        "def sample_sentence(unigram_count_map, bigram_count_map: dict, V: int, N: int) -> str:\n",
        "    # Sample first word based on unigram probability\n",
        "    trained_words = list(unigram_count_map.keys())\n",
        "    probabilities = [count / N for count in unigram_count_map.values()]\n",
        "    first_word = random.choices(trained_words, probabilities)[0] # ensures the random sampling is used to get the first word\n",
        "    generated_sentence = [first_word]\n",
        "\n",
        "    while first_word != \".\":\n",
        "        # Get possible next words based on bigram probability\n",
        "\n",
        "        # Find all bigrams where first_word is the first word. Gets a dictionary of all the possible succeeding words where\n",
        "        # the first word appears first in a bigram from the training corpus + how many times that bigram appears in the corpus overall\n",
        "        next_words = {bigram[1]: count for bigram, count in bigram_count_map.items() if bigram[0] == first_word}\n",
        "\n",
        "        if not next_words:  # no bigram transition is found, so we will end the loop because this word has no possible next_word\n",
        "            break\n",
        "\n",
        "        # get all normal bigram probabilities of the next_words\n",
        "        total_count = sum(next_words.values())\n",
        "        next_probs = [count / total_count for count in next_words.values()]\n",
        "\n",
        "        # sample next word, having the probabilities calculated above randomly selected, then append to final string\n",
        "        first_word = random.choices(list(next_words.keys()), next_probs)[0]\n",
        "        generated_sentence.append(first_word)\n",
        "\n",
        "    return \" \".join(generated_sentence).replace(\" .\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your homework answers\n",
        "Q1_answer = tokenize(preprocessed_texts)\n",
        "print(Q1_answer)\n",
        "Q2_uni_gram_count = get_unigram_count(Q1_answer)\n",
        "print(Q2_uni_gram_count)\n",
        "Q2_bi_gram_count = get_bigram_count(Q1_answer)\n",
        "print(Q2_bi_gram_count)\n",
        "V = len(Q2_uni_gram_count) # get every possible word that exists in ori_text corpus\n",
        "N = sum(Q2_uni_gram_count.values()) # get the total count of every unigram (so duplicates included)\n",
        "print(\"V: \", V)\n",
        "print(\"N: \", N)\n",
        "smooth_count_uni = get_probability_smoothing(Q2_uni_gram_count, V, N)\n",
        "print(\"smooth_count_uni: \", smooth_count_uni)\n",
        "\n",
        "smooth_count_bi = get_probability_smoothing(Q2_bi_gram_count, V, N)\n",
        "print(\"Q2_bi_gram_count: \", Q2_bi_gram_count)\n",
        "\n",
        "sentence_1 = '''Τρώω τυρί και ελιές τα σαββατοκύριακα.'''\n",
        "print(\"sentece 1: \", sentence_1)\n",
        "sentence_2 = '''Στην Ελλάδα, οι άνθρωποι απολαμβάνουν μια πλούσια ποικιλία τροφίμων που περιλαμβάνει φρέσκα θαλασσινά, λαχταριστά παραδοσιακά πιάτα όπως μουσακά και σουβλάκι, αρωματικά μπαχαρικά και βότανα, καθώς και μια εκπληκτική ποικιλία τυριών και ελιών, απολαμβάνοντας το φαγητό τους με καλό κρασί ή ούζο.'''\n",
        "print(\"sentece 2: \", sentence_2)\n",
        "\n",
        "\n",
        "Q3_sentence1_golden = estimate_probability_preplexity_product(sentence_1, smooth_count_uni, smooth_count_bi, V)\n",
        "print(\"Q3_sentence1_golden: \", Q3_sentence1_golden)\n",
        "\n",
        "Q3_sentence2_golden = estimate_probability_preplexity_product(sentence_2, smooth_count_uni, smooth_count_bi, V)\n",
        "print(\"Q3_sentence2_golden: \", Q3_sentence2_golden)\n",
        "\n",
        "Q4_sentence = sample_sentence(Q2_uni_gram_count, Q2_bi_gram_count, V, N)\n",
        "print(\"q4 sentence is: \", Q4_sentence)\n",
        "Q4_code = '''\n",
        "def sample_sentence(unigram_count_map, bigram_count_map: dict, V: int, N: int) -> str:\n",
        "    # Sample first word based on unigram probability\n",
        "    trained_words = list(unigram_count_map.keys())\n",
        "    probabilities = [count / N for count in unigram_count_map.values()]\n",
        "    first_word = random.choices(trained_words, probabilities)[0] # ensures the random sampling is used to get the first word\n",
        "    generated_sentence = [first_word]\n",
        "\n",
        "    while first_word != \".\":\n",
        "        # Get possible next words based on bigram probability\n",
        "\n",
        "        # Find all bigrams where first_word is the first word. Gets a dictionary of all the possible succeeding words where\n",
        "        # the first word appears first in a bigram from the training corpus + how many times that bigram appears in the corpus overall\n",
        "        next_words = {bigram[1]: count for bigram, count in bigram_count_map.items() if bigram[0] == first_word}\n",
        "\n",
        "        if not next_words:  # no bigram transition is found, so we will end the loop because this word has no possible next_word\n",
        "            break\n",
        "\n",
        "        # get all normal bigram probabilities of the next_words\n",
        "        total_count = sum(next_words.values())\n",
        "        next_probs = [count / total_count for count in next_words.values()]\n",
        "\n",
        "        # sample next word, having the probabilities calculated above randomly selected, then append to final string\n",
        "        first_word = random.choices(list(next_words.keys()), next_probs)[0]\n",
        "        generated_sentence.append(first_word)\n",
        "\n",
        "    return \" \".join(generated_sentence).replace(\" .\", \".\")\n",
        "''' # just copy your sample_sentence code here as a string\n",
        "print(Q4_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdZAbVijBdf8",
        "outputId": "20a65787-0565-46e7-85aa-5dfd7a5b185e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['τρώω', 'φρούτα', 'κάθε', 'μέρα', '.', 'τρώω', 'ψωμί', 'με', 'βούτυρο', '.', 'τρώω', 'ένα', 'μήλο', 'το', 'πρωί', '.', 'τρώω', 'σαλάτα', 'με', 'ντομάτα', '.', 'τρώω', 'ζυμαρικά', 'για', 'μεσημεριανό', '.', 'τρώω', 'κοτόπουλο', 'για', 'δείπνο', '.', 'τρώω', 'αυγά', 'το', 'σαββατοκύριακο', '.', 'τρώω', 'ρύζι', 'με', 'λαχανικά', '.', 'τρώω', 'γιαούρτι', 'με', 'μέλι', '.', 'τρώω', 'τυρί', 'και', 'ελιές', '.', 'αγαπώ', 'τα', 'φρούτα', ',', 'ειδικά', 'τα', 'μήλα', '.', 'έχεις', 'ψωμί', ';', 'κάθε', 'πρωί', 'τρώω', 'ένα', 'μήλο', '.', 'θέλω', 'να', 'φάω', 'σαλάτα', 'με', 'ντομάτες', '.', 'η', 'σούπα', 'έχει', 'κοτόπουλο', 'και', 'λαχανικά', '.', 'πόσο', 'κοστίζει', 'το', 'ψωμί', ';', 'πίνω', 'γάλα', 'με', 'το', 'μήλο', 'μου', '.', 'μετά', 'το', 'δείπνο', ',', 'τρώμε', 'συχνά', 'φρούτα', '.', 'στη', 'σαλάτα', ',', 'βάζω', 'πάντα', 'ντομάτες', '.', 'ποιος', 'έφαγε', 'το', 'ψωμί', ';', 'το', 'κοτόπουλο', 'είναι', 'το', 'αγαπημένο', 'μου', 'φαγητό', '.', 'μπορώ', 'να', 'έχω', 'λίγο', 'περισσότερο', 'ψωμί', ',', 'παρακαλώ', ';', 'αυτή', 'η', 'μηλόπιτα', 'είναι', 'πολύ', 'νόστιμη', '.', 'πού', 'αγόρασες', 'αυτά', 'τα', 'φρέσκα', 'φρούτα', ';', 'φτιάχνω', 'σαλάτα', 'με', 'ντομάτες', 'και', 'αγγούρια', '.', 'θα', 'πιείτε', 'γάλα', 'ή', 'χυμό', ';', 'τα', 'παιδιά', 'δεν', 'τρώνε', 'πολύ', 'ψωμί', '.', 'αυτές', 'οι', 'ντομάτες', 'είναι', 'πολύ', 'ώριμες', '.', 'στο', 'πρωινό', 'μου', 'πάντα', 'έχω', 'ένα', 'μήλο', '.', 'τα', 'φρούτα', 'είναι', 'καλά', 'για', 'την', 'υγεία', '.']\n",
            "{'τρώω': 11, 'φρούτα': 5, 'κάθε': 2, 'μέρα': 1, '.': 24, 'ψωμί': 6, 'με': 7, 'βούτυρο': 1, 'ένα': 3, 'μήλο': 4, 'το': 8, 'πρωί': 2, 'σαλάτα': 4, 'ντομάτα': 1, 'ζυμαρικά': 1, 'για': 3, 'μεσημεριανό': 1, 'κοτόπουλο': 3, 'δείπνο': 2, 'αυγά': 1, 'σαββατοκύριακο': 1, 'ρύζι': 1, 'λαχανικά': 2, 'γιαούρτι': 1, 'μέλι': 1, 'τυρί': 1, 'και': 3, 'ελιές': 1, 'αγαπώ': 1, 'τα': 5, ',': 4, 'ειδικά': 1, 'μήλα': 1, 'έχεις': 1, ';': 6, 'θέλω': 1, 'να': 2, 'φάω': 1, 'ντομάτες': 4, 'η': 2, 'σούπα': 1, 'έχει': 1, 'πόσο': 1, 'κοστίζει': 1, 'πίνω': 1, 'γάλα': 2, 'μου': 3, 'μετά': 1, 'τρώμε': 1, 'συχνά': 1, 'στη': 1, 'βάζω': 1, 'πάντα': 2, 'ποιος': 1, 'έφαγε': 1, 'είναι': 4, 'αγαπημένο': 1, 'φαγητό': 1, 'μπορώ': 1, 'έχω': 2, 'λίγο': 1, 'περισσότερο': 1, 'παρακαλώ': 1, 'αυτή': 1, 'μηλόπιτα': 1, 'πολύ': 3, 'νόστιμη': 1, 'πού': 1, 'αγόρασες': 1, 'αυτά': 1, 'φρέσκα': 1, 'φτιάχνω': 1, 'αγγούρια': 1, 'θα': 1, 'πιείτε': 1, 'ή': 1, 'χυμό': 1, 'παιδιά': 1, 'δεν': 1, 'τρώνε': 1, 'αυτές': 1, 'οι': 1, 'ώριμες': 1, 'στο': 1, 'πρωινό': 1, 'καλά': 1, 'την': 1, 'υγεία': 1}\n",
            "{('τρώω', 'φρούτα'): 1, ('φρούτα', 'κάθε'): 1, ('κάθε', 'μέρα'): 1, ('μέρα', '.'): 1, ('.', 'τρώω'): 9, ('τρώω', 'ψωμί'): 1, ('ψωμί', 'με'): 1, ('με', 'βούτυρο'): 1, ('βούτυρο', '.'): 1, ('τρώω', 'ένα'): 2, ('ένα', 'μήλο'): 3, ('μήλο', 'το'): 1, ('το', 'πρωί'): 1, ('πρωί', '.'): 1, ('τρώω', 'σαλάτα'): 1, ('σαλάτα', 'με'): 3, ('με', 'ντομάτα'): 1, ('ντομάτα', '.'): 1, ('τρώω', 'ζυμαρικά'): 1, ('ζυμαρικά', 'για'): 1, ('για', 'μεσημεριανό'): 1, ('μεσημεριανό', '.'): 1, ('τρώω', 'κοτόπουλο'): 1, ('κοτόπουλο', 'για'): 1, ('για', 'δείπνο'): 1, ('δείπνο', '.'): 1, ('τρώω', 'αυγά'): 1, ('αυγά', 'το'): 1, ('το', 'σαββατοκύριακο'): 1, ('σαββατοκύριακο', '.'): 1, ('τρώω', 'ρύζι'): 1, ('ρύζι', 'με'): 1, ('με', 'λαχανικά'): 1, ('λαχανικά', '.'): 2, ('τρώω', 'γιαούρτι'): 1, ('γιαούρτι', 'με'): 1, ('με', 'μέλι'): 1, ('μέλι', '.'): 1, ('τρώω', 'τυρί'): 1, ('τυρί', 'και'): 1, ('και', 'ελιές'): 1, ('ελιές', '.'): 1, ('.', 'αγαπώ'): 1, ('αγαπώ', 'τα'): 1, ('τα', 'φρούτα'): 2, ('φρούτα', ','): 1, (',', 'ειδικά'): 1, ('ειδικά', 'τα'): 1, ('τα', 'μήλα'): 1, ('μήλα', '.'): 1, ('.', 'έχεις'): 1, ('έχεις', 'ψωμί'): 1, ('ψωμί', ';'): 3, (';', 'κάθε'): 1, ('κάθε', 'πρωί'): 1, ('πρωί', 'τρώω'): 1, ('μήλο', '.'): 2, ('.', 'θέλω'): 1, ('θέλω', 'να'): 1, ('να', 'φάω'): 1, ('φάω', 'σαλάτα'): 1, ('με', 'ντομάτες'): 2, ('ντομάτες', '.'): 2, ('.', 'η'): 1, ('η', 'σούπα'): 1, ('σούπα', 'έχει'): 1, ('έχει', 'κοτόπουλο'): 1, ('κοτόπουλο', 'και'): 1, ('και', 'λαχανικά'): 1, ('.', 'πόσο'): 1, ('πόσο', 'κοστίζει'): 1, ('κοστίζει', 'το'): 1, ('το', 'ψωμί'): 2, (';', 'πίνω'): 1, ('πίνω', 'γάλα'): 1, ('γάλα', 'με'): 1, ('με', 'το'): 1, ('το', 'μήλο'): 1, ('μήλο', 'μου'): 1, ('μου', '.'): 1, ('.', 'μετά'): 1, ('μετά', 'το'): 1, ('το', 'δείπνο'): 1, ('δείπνο', ','): 1, (',', 'τρώμε'): 1, ('τρώμε', 'συχνά'): 1, ('συχνά', 'φρούτα'): 1, ('φρούτα', '.'): 1, ('.', 'στη'): 1, ('στη', 'σαλάτα'): 1, ('σαλάτα', ','): 1, (',', 'βάζω'): 1, ('βάζω', 'πάντα'): 1, ('πάντα', 'ντομάτες'): 1, ('.', 'ποιος'): 1, ('ποιος', 'έφαγε'): 1, ('έφαγε', 'το'): 1, (';', 'το'): 1, ('το', 'κοτόπουλο'): 1, ('κοτόπουλο', 'είναι'): 1, ('είναι', 'το'): 1, ('το', 'αγαπημένο'): 1, ('αγαπημένο', 'μου'): 1, ('μου', 'φαγητό'): 1, ('φαγητό', '.'): 1, ('.', 'μπορώ'): 1, ('μπορώ', 'να'): 1, ('να', 'έχω'): 1, ('έχω', 'λίγο'): 1, ('λίγο', 'περισσότερο'): 1, ('περισσότερο', 'ψωμί'): 1, ('ψωμί', ','): 1, (',', 'παρακαλώ'): 1, ('παρακαλώ', ';'): 1, (';', 'αυτή'): 1, ('αυτή', 'η'): 1, ('η', 'μηλόπιτα'): 1, ('μηλόπιτα', 'είναι'): 1, ('είναι', 'πολύ'): 2, ('πολύ', 'νόστιμη'): 1, ('νόστιμη', '.'): 1, ('.', 'πού'): 1, ('πού', 'αγόρασες'): 1, ('αγόρασες', 'αυτά'): 1, ('αυτά', 'τα'): 1, ('τα', 'φρέσκα'): 1, ('φρέσκα', 'φρούτα'): 1, ('φρούτα', ';'): 1, (';', 'φτιάχνω'): 1, ('φτιάχνω', 'σαλάτα'): 1, ('ντομάτες', 'και'): 1, ('και', 'αγγούρια'): 1, ('αγγούρια', '.'): 1, ('.', 'θα'): 1, ('θα', 'πιείτε'): 1, ('πιείτε', 'γάλα'): 1, ('γάλα', 'ή'): 1, ('ή', 'χυμό'): 1, ('χυμό', ';'): 1, (';', 'τα'): 1, ('τα', 'παιδιά'): 1, ('παιδιά', 'δεν'): 1, ('δεν', 'τρώνε'): 1, ('τρώνε', 'πολύ'): 1, ('πολύ', 'ψωμί'): 1, ('ψωμί', '.'): 1, ('.', 'αυτές'): 1, ('αυτές', 'οι'): 1, ('οι', 'ντομάτες'): 1, ('ντομάτες', 'είναι'): 1, ('πολύ', 'ώριμες'): 1, ('ώριμες', '.'): 1, ('.', 'στο'): 1, ('στο', 'πρωινό'): 1, ('πρωινό', 'μου'): 1, ('μου', 'πάντα'): 1, ('πάντα', 'έχω'): 1, ('έχω', 'ένα'): 1, ('.', 'τα'): 1, ('φρούτα', 'είναι'): 1, ('είναι', 'καλά'): 1, ('καλά', 'για'): 1, ('για', 'την'): 1, ('την', 'υγεία'): 1, ('υγεία', '.'): 1}\n",
            "V:  88\n",
            "N:  188\n",
            "smooth_count_uni:  {'τρώω': 0.043478260869565216, 'φρούτα': 0.021739130434782608, 'κάθε': 0.010869565217391304, 'μέρα': 0.007246376811594203, '.': 0.09057971014492754, 'ψωμί': 0.025362318840579712, 'με': 0.028985507246376812, 'βούτυρο': 0.007246376811594203, 'ένα': 0.014492753623188406, 'μήλο': 0.018115942028985508, 'το': 0.03260869565217391, 'πρωί': 0.010869565217391304, 'σαλάτα': 0.018115942028985508, 'ντομάτα': 0.007246376811594203, 'ζυμαρικά': 0.007246376811594203, 'για': 0.014492753623188406, 'μεσημεριανό': 0.007246376811594203, 'κοτόπουλο': 0.014492753623188406, 'δείπνο': 0.010869565217391304, 'αυγά': 0.007246376811594203, 'σαββατοκύριακο': 0.007246376811594203, 'ρύζι': 0.007246376811594203, 'λαχανικά': 0.010869565217391304, 'γιαούρτι': 0.007246376811594203, 'μέλι': 0.007246376811594203, 'τυρί': 0.007246376811594203, 'και': 0.014492753623188406, 'ελιές': 0.007246376811594203, 'αγαπώ': 0.007246376811594203, 'τα': 0.021739130434782608, ',': 0.018115942028985508, 'ειδικά': 0.007246376811594203, 'μήλα': 0.007246376811594203, 'έχεις': 0.007246376811594203, ';': 0.025362318840579712, 'θέλω': 0.007246376811594203, 'να': 0.010869565217391304, 'φάω': 0.007246376811594203, 'ντομάτες': 0.018115942028985508, 'η': 0.010869565217391304, 'σούπα': 0.007246376811594203, 'έχει': 0.007246376811594203, 'πόσο': 0.007246376811594203, 'κοστίζει': 0.007246376811594203, 'πίνω': 0.007246376811594203, 'γάλα': 0.010869565217391304, 'μου': 0.014492753623188406, 'μετά': 0.007246376811594203, 'τρώμε': 0.007246376811594203, 'συχνά': 0.007246376811594203, 'στη': 0.007246376811594203, 'βάζω': 0.007246376811594203, 'πάντα': 0.010869565217391304, 'ποιος': 0.007246376811594203, 'έφαγε': 0.007246376811594203, 'είναι': 0.018115942028985508, 'αγαπημένο': 0.007246376811594203, 'φαγητό': 0.007246376811594203, 'μπορώ': 0.007246376811594203, 'έχω': 0.010869565217391304, 'λίγο': 0.007246376811594203, 'περισσότερο': 0.007246376811594203, 'παρακαλώ': 0.007246376811594203, 'αυτή': 0.007246376811594203, 'μηλόπιτα': 0.007246376811594203, 'πολύ': 0.014492753623188406, 'νόστιμη': 0.007246376811594203, 'πού': 0.007246376811594203, 'αγόρασες': 0.007246376811594203, 'αυτά': 0.007246376811594203, 'φρέσκα': 0.007246376811594203, 'φτιάχνω': 0.007246376811594203, 'αγγούρια': 0.007246376811594203, 'θα': 0.007246376811594203, 'πιείτε': 0.007246376811594203, 'ή': 0.007246376811594203, 'χυμό': 0.007246376811594203, 'παιδιά': 0.007246376811594203, 'δεν': 0.007246376811594203, 'τρώνε': 0.007246376811594203, 'αυτές': 0.007246376811594203, 'οι': 0.007246376811594203, 'ώριμες': 0.007246376811594203, 'στο': 0.007246376811594203, 'πρωινό': 0.007246376811594203, 'καλά': 0.007246376811594203, 'την': 0.007246376811594203, 'υγεία': 0.007246376811594203}\n",
            "Q2_bi_gram_count:  {('τρώω', 'φρούτα'): 1, ('φρούτα', 'κάθε'): 1, ('κάθε', 'μέρα'): 1, ('μέρα', '.'): 1, ('.', 'τρώω'): 9, ('τρώω', 'ψωμί'): 1, ('ψωμί', 'με'): 1, ('με', 'βούτυρο'): 1, ('βούτυρο', '.'): 1, ('τρώω', 'ένα'): 2, ('ένα', 'μήλο'): 3, ('μήλο', 'το'): 1, ('το', 'πρωί'): 1, ('πρωί', '.'): 1, ('τρώω', 'σαλάτα'): 1, ('σαλάτα', 'με'): 3, ('με', 'ντομάτα'): 1, ('ντομάτα', '.'): 1, ('τρώω', 'ζυμαρικά'): 1, ('ζυμαρικά', 'για'): 1, ('για', 'μεσημεριανό'): 1, ('μεσημεριανό', '.'): 1, ('τρώω', 'κοτόπουλο'): 1, ('κοτόπουλο', 'για'): 1, ('για', 'δείπνο'): 1, ('δείπνο', '.'): 1, ('τρώω', 'αυγά'): 1, ('αυγά', 'το'): 1, ('το', 'σαββατοκύριακο'): 1, ('σαββατοκύριακο', '.'): 1, ('τρώω', 'ρύζι'): 1, ('ρύζι', 'με'): 1, ('με', 'λαχανικά'): 1, ('λαχανικά', '.'): 2, ('τρώω', 'γιαούρτι'): 1, ('γιαούρτι', 'με'): 1, ('με', 'μέλι'): 1, ('μέλι', '.'): 1, ('τρώω', 'τυρί'): 1, ('τυρί', 'και'): 1, ('και', 'ελιές'): 1, ('ελιές', '.'): 1, ('.', 'αγαπώ'): 1, ('αγαπώ', 'τα'): 1, ('τα', 'φρούτα'): 2, ('φρούτα', ','): 1, (',', 'ειδικά'): 1, ('ειδικά', 'τα'): 1, ('τα', 'μήλα'): 1, ('μήλα', '.'): 1, ('.', 'έχεις'): 1, ('έχεις', 'ψωμί'): 1, ('ψωμί', ';'): 3, (';', 'κάθε'): 1, ('κάθε', 'πρωί'): 1, ('πρωί', 'τρώω'): 1, ('μήλο', '.'): 2, ('.', 'θέλω'): 1, ('θέλω', 'να'): 1, ('να', 'φάω'): 1, ('φάω', 'σαλάτα'): 1, ('με', 'ντομάτες'): 2, ('ντομάτες', '.'): 2, ('.', 'η'): 1, ('η', 'σούπα'): 1, ('σούπα', 'έχει'): 1, ('έχει', 'κοτόπουλο'): 1, ('κοτόπουλο', 'και'): 1, ('και', 'λαχανικά'): 1, ('.', 'πόσο'): 1, ('πόσο', 'κοστίζει'): 1, ('κοστίζει', 'το'): 1, ('το', 'ψωμί'): 2, (';', 'πίνω'): 1, ('πίνω', 'γάλα'): 1, ('γάλα', 'με'): 1, ('με', 'το'): 1, ('το', 'μήλο'): 1, ('μήλο', 'μου'): 1, ('μου', '.'): 1, ('.', 'μετά'): 1, ('μετά', 'το'): 1, ('το', 'δείπνο'): 1, ('δείπνο', ','): 1, (',', 'τρώμε'): 1, ('τρώμε', 'συχνά'): 1, ('συχνά', 'φρούτα'): 1, ('φρούτα', '.'): 1, ('.', 'στη'): 1, ('στη', 'σαλάτα'): 1, ('σαλάτα', ','): 1, (',', 'βάζω'): 1, ('βάζω', 'πάντα'): 1, ('πάντα', 'ντομάτες'): 1, ('.', 'ποιος'): 1, ('ποιος', 'έφαγε'): 1, ('έφαγε', 'το'): 1, (';', 'το'): 1, ('το', 'κοτόπουλο'): 1, ('κοτόπουλο', 'είναι'): 1, ('είναι', 'το'): 1, ('το', 'αγαπημένο'): 1, ('αγαπημένο', 'μου'): 1, ('μου', 'φαγητό'): 1, ('φαγητό', '.'): 1, ('.', 'μπορώ'): 1, ('μπορώ', 'να'): 1, ('να', 'έχω'): 1, ('έχω', 'λίγο'): 1, ('λίγο', 'περισσότερο'): 1, ('περισσότερο', 'ψωμί'): 1, ('ψωμί', ','): 1, (',', 'παρακαλώ'): 1, ('παρακαλώ', ';'): 1, (';', 'αυτή'): 1, ('αυτή', 'η'): 1, ('η', 'μηλόπιτα'): 1, ('μηλόπιτα', 'είναι'): 1, ('είναι', 'πολύ'): 2, ('πολύ', 'νόστιμη'): 1, ('νόστιμη', '.'): 1, ('.', 'πού'): 1, ('πού', 'αγόρασες'): 1, ('αγόρασες', 'αυτά'): 1, ('αυτά', 'τα'): 1, ('τα', 'φρέσκα'): 1, ('φρέσκα', 'φρούτα'): 1, ('φρούτα', ';'): 1, (';', 'φτιάχνω'): 1, ('φτιάχνω', 'σαλάτα'): 1, ('ντομάτες', 'και'): 1, ('και', 'αγγούρια'): 1, ('αγγούρια', '.'): 1, ('.', 'θα'): 1, ('θα', 'πιείτε'): 1, ('πιείτε', 'γάλα'): 1, ('γάλα', 'ή'): 1, ('ή', 'χυμό'): 1, ('χυμό', ';'): 1, (';', 'τα'): 1, ('τα', 'παιδιά'): 1, ('παιδιά', 'δεν'): 1, ('δεν', 'τρώνε'): 1, ('τρώνε', 'πολύ'): 1, ('πολύ', 'ψωμί'): 1, ('ψωμί', '.'): 1, ('.', 'αυτές'): 1, ('αυτές', 'οι'): 1, ('οι', 'ντομάτες'): 1, ('ντομάτες', 'είναι'): 1, ('πολύ', 'ώριμες'): 1, ('ώριμες', '.'): 1, ('.', 'στο'): 1, ('στο', 'πρωινό'): 1, ('πρωινό', 'μου'): 1, ('μου', 'πάντα'): 1, ('πάντα', 'έχω'): 1, ('έχω', 'ένα'): 1, ('.', 'τα'): 1, ('φρούτα', 'είναι'): 1, ('είναι', 'καλά'): 1, ('καλά', 'για'): 1, ('για', 'την'): 1, ('την', 'υγεία'): 1, ('υγεία', '.'): 1}\n",
            "sentece 1:  Τρώω τυρί και ελιές τα σαββατοκύριακα.\n",
            "sentece 2:  Στην Ελλάδα, οι άνθρωποι απολαμβάνουν μια πλούσια ποικιλία τροφίμων που περιλαμβάνει φρέσκα θαλασσινά, λαχταριστά παραδοσιακά πιάτα όπως μουσακά και σουβλάκι, αρωματικά μπαχαρικά και βότανα, καθώς και μια εκπληκτική ποικιλία τυριών και ελιών, απολαμβάνοντας το φαγητό τους με καλό κρασί ή ούζο.\n",
            "Q3_sentence1_golden:  (8.756108584133473e-13, 52.78699992682569)\n",
            "Q3_sentence2_golden:  (3.5792915990307796e-90, 80.00381564218326)\n",
            "q4 sentence is:  έχει κοτόπουλο και αγγούρια.\n",
            "\n",
            "def sample_sentence(unigram_count_map, bigram_count_map: dict, V: int, N: int) -> str:\n",
            "    # Sample first word based on unigram probability\n",
            "    trained_words = list(unigram_count_map.keys())\n",
            "    probabilities = [count / N for count in unigram_count_map.values()]\n",
            "    first_word = random.choices(trained_words, probabilities)[0] # ensures the random sampling is used to get the first word\n",
            "    generated_sentence = [first_word]\n",
            "\n",
            "    while first_word != \".\":\n",
            "        # Get possible next words based on bigram probability\n",
            "\n",
            "        # Find all bigrams where first_word is the first word. Gets a dictionary of all the possible succeeding words where\n",
            "        # the first word appears first in a bigram from the training corpus + how many times that bigram appears in the corpus overall\n",
            "        next_words = {bigram[1]: count for bigram, count in bigram_count_map.items() if bigram[0] == first_word}\n",
            "\n",
            "        if not next_words:  # no bigram transition is found, so we will end the loop because this word has no possible next_word\n",
            "            break\n",
            "\n",
            "        # get all normal bigram probabilities of the next_words\n",
            "        total_count = sum(next_words.values())\n",
            "        next_probs = [count / total_count for count in next_words.values()]\n",
            "\n",
            "        # sample next word, having the probabilities calculated above randomly selected, then append to final string\n",
            "        first_word = random.choices(list(next_words.keys()), next_probs)[0]\n",
            "        generated_sentence.append(first_word)\n",
            "\n",
            "    return \" \".join(generated_sentence).replace(\" .\", \".\")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q2_bi_gram_count_str_key = {i[0][0]+'|'+i[0][1]:i[1] for i in Q2_bi_gram_count.items()}\n",
        "result_dict = {\n",
        "\"UNI\": \"hbh180000\", # Enter your university ID (e.g., \"kxa190001\"), ensure it's a string\n",
        "'First_name': \"Haniyyah\", # Enter your first name here, ensure it's a string\n",
        "\"Last_name\": \"Hamid\", # Enter your last name here, ensure it's a string\n",
        "'Q1': Q1_answer, # Q1 answer should be a list of tokens\n",
        "'Q2_uni': Q2_uni_gram_count, # Q2_uni should be a dict, keys are the tokens and values are int\n",
        "                            # - Key: Word as a string (e.g., \"\")\n",
        "                            # - Value: Frequency count (in\n",
        "'Q2_bi': Q2_bi_gram_count_str_key, # Q2_bi should be a dict, keys are strings of token and values are int\n",
        "                                  # - Key: Tuple of \"previous_word, next_word\" this is a string\n",
        "                                  # two tokens are separate with a \"|\", Make sure the key is a string\n",
        "                                  # - Value: Co-occurrence count (int)\n",
        "'Q3_sentence1': Q3_sentence1_golden,# List [Probability, perplexity]\n",
        "'Q3_sentence2': Q3_sentence2_golden,# List [Probability, perplexity]\n",
        "'Q4_sentence': Q4_sentence, # Your generated sentence, should be a string.\n",
        "'Q4_code': Q4_code # Your code for Q4 to generate the sentence, should be a string\n",
        "}\n"
      ],
      "metadata": {
        "id": "F67muhz3BerU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check your dict\n",
        "def validate_result_dict(result_dict):\n",
        "  \"\"\"\n",
        "  Validate the structure and types of the result_dict.\n",
        "  Returns:\n",
        "  Tuple[bool, str]: (True, \"Validation Passed\") if all checks pass,\n",
        "  (False, \"Error message\") otherwise.\n",
        "  \"\"\"\n",
        "  expected_types = {\n",
        "  \"UNI\": str,\n",
        "  \"First_name\": str,\n",
        "  \"Last_name\": str,\n",
        "  \"Q1\": list, # Should be a list of tokens (strings)\n",
        "  \"Q2_uni\": dict, # Should be a dictionary {str: int}\n",
        "  \"Q2_bi\": dict, # Should be a dictionary {str: int}, keys are formatted as \"word1|word2\"\n",
        "  \"Q3_sentence1\": (list, tuple), # Should be a list or tuple [float, float] (Probability, Perplexity)\n",
        "  \"Q3_sentence2\": (list, tuple), # Should be a list or tuple [float,float] (Probability, Perplexity)\n",
        "  \"Q4_sentence\": str, # Should be a string\n",
        "  \"Q4_code\": str # Should be a string\n",
        "  }\n",
        "\n",
        "  # Check if all required keys exist\n",
        "  missing_keys = [key for key in expected_types if key not in result_dict]\n",
        "  if missing_keys:\n",
        "    return False, f\"Missing keys in result_dict: {missing_keys}\"\n",
        "  3\n",
        "  # Check types of each key\n",
        "  for key, expected_type in expected_types.items():\n",
        "    if not isinstance(result_dict[key], expected_type):\n",
        "      return False, f\"Key '{key}' has incorrect type. Expected {expected_type}, got {type(result_dict[key])}.\"\n",
        "\n",
        "  # Check if Q1 is a list of strings\n",
        "  if not all(isinstance(item, str) for item in result_dict[\"Q1\"]):\n",
        "    return False, \"Q1 should be a list of strings (tokens).\"\n",
        "  # Check if Q2_uni is a dictionary with {str: int}\n",
        "  if not all(isinstance(k, str) and isinstance(v, int) for k, v in result_dict[\"Q2_uni\"].items()):\n",
        "    return False, \"Q2_uni should be a dictionary with string keys and integer values.\"\n",
        "  # Check if Q2_bi is a dictionary with {str: int} and keys contain \"|\"\n",
        "  if not all(isinstance(k, str) and \"|\" in k and isinstance(v, int) for k, v in result_dict[\"Q2_bi\"].items()):\n",
        "    return False, \"Q2_bi should be a dictionary with keys as 'word1|word2' strings and integer values.\"\n",
        "  # Check if Q3_sentence1 and Q3_sentence2 are lists or tuples of two floats\n",
        "  for key in [\"Q3_sentence1\", \"Q3_sentence2\"]:\n",
        "    if not (isinstance(result_dict[key], (list, tuple)) and len(result_dict[key]) == 2 and all(isinstance(x, (int, float)) for x in result_dict[key])):\n",
        "      return False, f\"{key} should be a list or tuple of two numeric values (Probability, Perplexity).\"\n",
        "    return True, \"Validation Passed\"\n",
        "  result = validate_result_dict(result_dict)\n",
        "  if result[0]:\n",
        "    print(\" Validation Passed!\")\n",
        "  else:\n",
        "    print(f\" Validation Failed: {result[1]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4rvlCgZYBt9m"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and submit your result\n",
        "import json\n",
        "# Convert dictionary to JSON string\n",
        "json_data = json.dumps(result_dict, indent=4) # Use indent for pretty-printing\n",
        "# Save JSON to a file\n",
        "with open(\"assignment1_answer.json\", \"w\") as json_file: # Don't change the name here\n",
        "\n",
        "  json.dump(result_dict, json_file, indent=4, ensure_ascii=False) # Use indent for pretty-printing\n",
        "\n",
        "files.download(\"assignment1_answer.json\")\n"
      ],
      "metadata": {
        "id": "ibBQCaxeGhBe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1f919fe7-8c6c-4764-847b-5af1f6808926"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4dba65b4-2283-4d51-8724-fa2966c161cf\", \"assignment1_answer.json\", 13074)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}